{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def save_data(group_data,output_feature,output_group):\n",
    "    if len(group_data) == 0:\n",
    "        return\n",
    "\n",
    "    output_group.write(str(len(group_data))+\"\\n\")\n",
    "    for data in group_data:\n",
    "        # only include nonzero features\n",
    "        feats = [ p for p in data[2:] if float(p.split(':')[1]) != 0.0 ]        \n",
    "        output_feature.write(data[0] + \" \" + \" \".join(feats) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(datafile, featurefile, groupfile):\n",
    "    \n",
    "    fi = open(datafile)\n",
    "    output_feature = open(featurefile,\"w\")\n",
    "    output_group = open(groupfile,\"w\")\n",
    "    \n",
    "    group_data = []\n",
    "    group = \"\"\n",
    "    for line in fi:\n",
    "        if not line:\n",
    "            break\n",
    "        if \"#\" in line:\n",
    "            line = line[:line.index(\"#\")]\n",
    "        splits = line.strip().split(\" \")\n",
    "        if splits[1] != group:\n",
    "            save_data(group_data,output_feature,output_group)\n",
    "            group_data = []\n",
    "        group = splits[1]\n",
    "        group_data.append(splits)\n",
    "\n",
    "    save_data(group_data,output_feature,output_group)\n",
    "\n",
    "    fi.close()\n",
    "    output_feature.close()\n",
    "    output_group.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'MQ2008/Fold1/train.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m prepare_data(\u001b[39m'\u001b[39;49m\u001b[39mMQ2008/Fold1/train.txt\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mmq2008.train\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mmq2008.train.group\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m prepare_data(\u001b[39m'\u001b[39m\u001b[39mMQ2008/Fold1/test.txt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmq2008.test\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmq2008.test.group\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m prepare_data(\u001b[39m'\u001b[39m\u001b[39mMQ2008/Fold1/vali.txt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmq2008.vali\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmq2008.vali.group\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m, in \u001b[0;36mprepare_data\u001b[0;34m(datafile, featurefile, groupfile)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprepare_data\u001b[39m(datafile, featurefile, groupfile):\n\u001b[0;32m----> 3\u001b[0m     fi \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(datafile)\n\u001b[1;32m      4\u001b[0m     output_feature \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(featurefile,\u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     output_group \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(groupfile,\u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'MQ2008/Fold1/train.txt'"
     ]
    }
   ],
   "source": [
    "prepare_data('MQ2008/Fold1/train.txt', 'mq2008.train', 'mq2008.train.group')\n",
    "prepare_data('MQ2008/Fold1/test.txt', 'mq2008.test', 'mq2008.test.group')\n",
    "prepare_data('MQ2008/Fold1/vali.txt', 'mq2008.vali', 'mq2008.vali.group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msklearn\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m load_svmlight_file\n\u001b[1;32m      3\u001b[0m x_train, y_train \u001b[39m=\u001b[39m load_svmlight_file(\u001b[39m\"\u001b[39m\u001b[39mmq2008.train\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "x_train, y_train = load_svmlight_file(\"mq2008.train\")\n",
    "x_valid, y_valid = load_svmlight_file(\"mq2008.vali\")\n",
    "x_test, y_test = load_svmlight_file(\"mq2008.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "q_train = np.loadtxt('mq2008.train.group')\n",
    "q_valid = np.loadtxt('mq2008.vali.group')\n",
    "q_test = np.loadtxt('mq2008.test.group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9630.0 (9630, 46)\n"
     ]
    }
   ],
   "source": [
    "print(sum(q_train), x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's ndcg@1: 0\tvalid_0's ndcg@3: 0\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.567973\n",
      "[3]\tvalid_0's ndcg@1: 0.333333\tvalid_0's ndcg@3: 0.156426\n",
      "[4]\tvalid_0's ndcg@1: 0\tvalid_0's ndcg@3: 0.333333\n",
      "[5]\tvalid_0's ndcg@1: 0\tvalid_0's ndcg@3: 0.0782131\n",
      "[6]\tvalid_0's ndcg@1: 0\tvalid_0's ndcg@3: 0.098694\n",
      "[7]\tvalid_0's ndcg@1: 0\tvalid_0's ndcg@3: 0.176907\n",
      "[8]\tvalid_0's ndcg@1: 0\tvalid_0's ndcg@3: 0.176907\n",
      "[9]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.469279\n",
      "[10]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.469279\n",
      "[11]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.469279\n",
      "[12]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.469279\n",
      "[13]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.547492\n",
      "[14]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.547492\n",
      "[15]\tvalid_0's ndcg@1: 0.333333\tvalid_0's ndcg@3: 0.391066\n",
      "[16]\tvalid_0's ndcg@1: 0.333333\tvalid_0's ndcg@3: 0.156426\n",
      "[17]\tvalid_0's ndcg@1: 0.333333\tvalid_0's ndcg@3: 0.391066\n",
      "[18]\tvalid_0's ndcg@1: 0.333333\tvalid_0's ndcg@3: 0.452508\n",
      "[19]\tvalid_0's ndcg@1: 0\tvalid_0's ndcg@3: 0.333333\n",
      "[20]\tvalid_0's ndcg@1: 0\tvalid_0's ndcg@3: 0.176907\n",
      "[21]\tvalid_0's ndcg@1: 0.333333\tvalid_0's ndcg@3: 0.48976\n",
      "[22]\tvalid_0's ndcg@1: 0.333333\tvalid_0's ndcg@3: 0.48976\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.567973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRanker(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "           importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "           min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "           n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "           random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "           subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "gbm = lgb.LGBMRanker()\n",
    "\n",
    "gbm.fit(x_train, y_train, group=q_train, eval_set=[(x_valid, y_valid)], \n",
    "        eval_group=[q_valid], eval_at=[1, 3], early_stopping_rounds=20, \n",
    "        verbose=True, callbacks=[lgb.reset_parameter(learning_rate=lambda x: 0.95 ** x * 0.1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.3843555632065391, pvalue=0.0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "preds_train = gbm.predict(x_train)\n",
    "spearmanr(y_train, preds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9630]\n",
      "[1]\tvalid_0's ndcg@1: 0\tvalid_0's ndcg@3: 0\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's ndcg@1: 0\tvalid_0's ndcg@3: 0.098694\n",
      "[3]\tvalid_0's ndcg@1: 0\tvalid_0's ndcg@3: 0.0782131\n",
      "[4]\tvalid_0's ndcg@1: 0\tvalid_0's ndcg@3: 0.0782131\n",
      "[5]\tvalid_0's ndcg@1: 0\tvalid_0's ndcg@3: 0.0782131\n",
      "[6]\tvalid_0's ndcg@1: 0\tvalid_0's ndcg@3: 0.333333\n",
      "[7]\tvalid_0's ndcg@1: 0\tvalid_0's ndcg@3: 0.333333\n",
      "[8]\tvalid_0's ndcg@1: 0\tvalid_0's ndcg@3: 0.333333\n",
      "[9]\tvalid_0's ndcg@1: 0\tvalid_0's ndcg@3: 0.333333\n",
      "[10]\tvalid_0's ndcg@1: 0\tvalid_0's ndcg@3: 0.333333\n",
      "[11]\tvalid_0's ndcg@1: 0.333333\tvalid_0's ndcg@3: 0.687148\n",
      "[12]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.843574\n",
      "[13]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.843574\n",
      "[14]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.843574\n",
      "[15]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.843574\n",
      "[16]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.843574\n",
      "[17]\tvalid_0's ndcg@1: 0.333333\tvalid_0's ndcg@3: 0.530721\n",
      "[18]\tvalid_0's ndcg@1: 0.333333\tvalid_0's ndcg@3: 0.530721\n",
      "[19]\tvalid_0's ndcg@1: 0.333333\tvalid_0's ndcg@3: 0.530721\n",
      "[20]\tvalid_0's ndcg@1: 0.333333\tvalid_0's ndcg@3: 0.530721\n",
      "[21]\tvalid_0's ndcg@1: 0.333333\tvalid_0's ndcg@3: 0.530721\n",
      "[22]\tvalid_0's ndcg@1: 0.333333\tvalid_0's ndcg@3: 0.530721\n",
      "[23]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.802612\n",
      "[24]\tvalid_0's ndcg@1: 0.333333\tvalid_0's ndcg@3: 0.687148\n",
      "[25]\tvalid_0's ndcg@1: 0.333333\tvalid_0's ndcg@3: 0.687148\n",
      "[26]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\n",
      "[27]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\n",
      "[28]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\n",
      "[29]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\n",
      "[30]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.646186\n",
      "[31]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.646186\n",
      "[32]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.646186\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.843574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRanker(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "           importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "           min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "           n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "           random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "           subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_train = [x_train.shape[0]]\n",
    "q_valid = [x_valid.shape[0]]\n",
    "q_test = [x_test.shape[0]]\n",
    "print(q_train)\n",
    "gbm = lgb.LGBMRanker()\n",
    "gbm.fit(x_train, y_train, group=q_train, eval_set=[(x_valid, y_valid)],\n",
    "eval_group=[q_valid], eval_at=[1, 3], early_stopping_rounds=20, verbose=True,\n",
    "callbacks=[lgb.reset_parameter(learning_rate=lambda x: 0.95 ** x * 0.1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.4481291965266587, pvalue=0.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_train = gbm.predict(x_train)\n",
    "spearmanr(y_train, preds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9630"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8.,   8.,   8.,   8.,   8.,  16.,   8., 118.,  16.,   8.,   8.,\n",
       "         8.,   7.,   8.,  16.,   8.,  16.,   8.,  32.,   8.,   8.,   8.,\n",
       "        31.,   8.,   8.,  15.,   8.,  15.,   8.,  28.,   7.,  62.,   8.,\n",
       "         8.,  16.,  16.,   8.,   8.,  15.,   8., 118.,   8.,  16.,   8.,\n",
       "         8.,  16.,  16.,   8.,  16.,   8.,   8.,   8.,   8.,   8.,  16.,\n",
       "         8.,  30.,   8.,   8.,   8.,   8.,   8.,  28.,   8., 113.,   7.,\n",
       "        15.,  25.,   8.,  16.,   8.,  16.,  59.,   8.,   7.,   8.,  31.,\n",
       "        30.,  31.,  32.,   8.,   8.,  16.,   8.,  31.,  15.,  15.,  28.,\n",
       "        32.,   8.,  31.,  59.,   8.,   7.,  55.,   8.,   8.,   8.,  32.,\n",
       "         7.,   8.,  16.,  58.,   8.,  15.,  29.,   8.,  31.,   8.,   8.,\n",
       "        16.,   8.,   8.,   6.,   8.,  62.,   8.,   8.,  60.,   8.,   8.,\n",
       "         8.,   8.,   8.,   8.,   7.,   8.,  16.,  13.,   8.,   7.,   8.,\n",
       "         8.,   8.,   8., 114.,  15.,  31.,   8.,   7.,   8.,   8.,  29.,\n",
       "         7.,  25.,   8.,   8.,   8., 118.,   7.,   8.,  26.,   8.,   8.,\n",
       "        30.,  14., 118.,   8.,   8.,  16.,   6.,   8.,   8.,  63.,   7.,\n",
       "         8.,  30.,  61.,   8.,  13.,  32.,  14., 115.,  30.,   8.,   8.,\n",
       "        59.,  31.,   8.,   8.,  16.,   7.,   8.,   8.,  15.,  15.,  63.,\n",
       "        60.,   8.,   8.,   8.,  16.,  15.,  16.,   8., 116.,   8.,  16.,\n",
       "         8.,   8.,  29.,  16.,  15.,  16.,   8.,   8.,  31.,   8.,  57.,\n",
       "         5.,   8.,  16.,  26.,  59.,   8.,  14.,   8., 121.,  16.,  31.,\n",
       "         8.,   8.,  16.,   7.,   8.,   8.,   8.,  13., 119.,  15.,   8.,\n",
       "        29.,  60.,  46.,  16.,   8.,   7.,   8.,  59.,  15.,   8.,  14.,\n",
       "         8.,   8.,  16.,   8., 116.,  16.,   8.,   8.,  30.,  16.,  13.,\n",
       "        15.,  31.,  16.,  30.,  13.,   8.,   8.,  31.,   8., 116.,   8.,\n",
       "        16.,   8.,   8.,  16.,   8.,  31.,   8.,  15.,   7., 115.,  59.,\n",
       "         8.,   8.,  59.,  59.,   8.,  14.,  32.,   8.,   8.,   8.,  31.,\n",
       "        32.,   8.,   8.,   8.,   8.,   8.,  30.,  30., 118.,   8.,   8.,\n",
       "         7.,  31.,   6.,   8.,  26.,  14.,  16.,   8.,  29.,  16.,  58.,\n",
       "         8.,  15.,   8.,   8.,  58.,  16.,  16., 111.,   8.,   8.,  15.,\n",
       "        29.,  16.,  16.,   8.,  15.,   8.,  32.,   8.,  15.,   8.,   8.,\n",
       "        16.,   8.,   8.,  14.,   7.,   8.,  16.,  56.,   8.,  31.,  16.,\n",
       "        32.,  29.,  15.,  15.,   8.,  58.,   8.,  15.,   7.,   8.,   7.,\n",
       "         8.,  24.,   8.,  51.,  30.,   8.,  57.,   5.,   8.,   8.,   8.,\n",
       "         7.,  31.,  16.,   8.,   8.,  31.,  16.,  32.,  15.,   7.,   7.,\n",
       "        14.,  16.,  15.,  16.,   8.,  60.,   8.,  58.,  16.,  29.,   8.,\n",
       "        29.,  15.,   8.,   8.,  16.,   8.,   8.,   8., 117.,  16.,   8.,\n",
       "         8.,  30.,   8.,   7.,  60.,   6.,  16.,   8.,  61.,   8.,   8.,\n",
       "        16.,   8.,  16.,  32.,   8.,   8.,   8.,  29.,   8.,  31.,  16.,\n",
       "         8.,  15.,   8.,  15.,  15.,   7.,  16.,   7.,  29.,  16.,   8.,\n",
       "        14.,   7.,  11.,   7.,   6., 119.,   8.,   8.,   8.,  16.,   8.,\n",
       "        16.,   8.,   7.,  16.,  31.,  16.,   8.,  32.,  31.,  31., 113.,\n",
       "         8.,  16.,  15.,  15.,  16.,  16.,   8.,   8.,   8.,   8.,  32.,\n",
       "         8.,  61.,   7.,  14.,  16.,   8., 117.,  15.,   8.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_train = np.loadtxt('mq2008.train.group')\n",
    "q_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
